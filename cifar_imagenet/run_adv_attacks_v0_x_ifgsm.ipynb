{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4660\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4619\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4689\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4657\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4637\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4648\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4667\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4623\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4663\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4692\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4718\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4713\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4650\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4687\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4649\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4673\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4690\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4636\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4666\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4689\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4694\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4727\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4677\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4678\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4697\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4681\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4740\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4711\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4683\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4710\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4700\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4714\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4712\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4702\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4686\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4722\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4707\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4723\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4691\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4715\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4685\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4732\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4732\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4730\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4723\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4685\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4748\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4688\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4761\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4745\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4693\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4788\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4701\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4709\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4680\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4693\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4728\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4725\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4704\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4705\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  4711\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4718\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4687\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  4743\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2_vo0'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4695\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         2392337 function calls (2217595 primitive calls) in 70.372 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "    20300   25.871    0.001   25.871    0.001 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "        6   13.844    2.307   13.844    2.307 {built-in method numpy.core.multiarray.array}\n",
       "     2000   12.300    0.006   12.300    0.006 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "    48300    3.362    0.000    3.362    0.000 {built-in method conv2d}\n",
       "    18900    2.255    0.000   10.848    0.001 nagpreresnet_learned_v2_vo0.py:39(forward)\n",
       "    39900    1.958    0.000    1.958    0.000 {built-in method batch_norm}\n",
       "        4    1.855    0.464    1.855    0.464 {built-in method posix.fork}\n",
       "       10    1.263    0.126    1.263    0.126 {built-in method posix.waitpid}\n",
       "170000/4100    1.156    0.000   12.338    0.003 module.py:537(__call__)\n",
       "    39900    0.919    0.000    0.919    0.000 {built-in method relu_}\n",
       "        1    0.497    0.497   70.369   70.369 Attack_Foolbox_ResNet20.py:4(<module>)\n",
       "   426460    0.464    0.000    0.467    0.000 module.py:577(__getattr__)\n",
       "      100    0.438    0.004   25.585    0.256 attack_toolbox.py:35(pgd_whitebox)\n",
       "    39900    0.312    0.000    2.701    0.000 batchnorm.py:58(forward)\n",
       "     1781    0.273    0.000    0.273    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "      123    0.260    0.002    0.260    0.002 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       "   170000    0.242    0.000    0.242    0.000 {built-in method torch._C._get_tracing_state}\n",
       "     6000    0.177    0.000    0.177    0.000 {built-in method clamp}\n",
       "    48300    0.177    0.000    3.568    0.000 conv.py:332(conv2d_forward)\n",
       "   354767    0.165    0.000    0.165    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "    39900    0.150    0.000    2.187    0.000 functional.py:1629(batch_norm)\n",
       "    48300    0.138    0.000    3.745    0.000 conv.py:342(forward)\n",
       "     2100    0.104    0.000    0.104    0.000 {built-in method addmm}\n",
       "14700/6300    0.103    0.000   11.157    0.002 container.py:90(forward)\n",
       "     2100    0.098    0.000   12.126    0.006 nagpreresnet_learned_v2_vo0.py:165(forward)\n",
       "192483/192482    0.097    0.000    0.097    0.000 {built-in method builtins.len}\n",
       "    25219    0.094    0.000    0.148    0.000 module.py:593(__setattr__)\n",
       "     2627    0.083    0.000    0.083    0.000 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "     2000    0.078    0.000    0.078    0.000 {method 'sign' of 'torch._C._TensorBase' objects}\n",
       "    39900    0.078    0.000    1.069    0.000 activation.py:93(forward)\n",
       "    39900    0.073    0.000    0.991    0.000 functional.py:903(relu)\n",
       "     2000    0.061    0.000    0.061    0.000 {built-in method torch._C._nn.nll_loss}\n",
       "      192    0.061    0.000    0.061    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
       "     2100    0.059    0.000    0.059    0.000 {built-in method zeros_like}\n",
       "     2000    0.058    0.000    0.058    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
       "     2100    0.056    0.000    0.056    0.000 {built-in method torch._C._nn.avg_pool2d}\n",
       "     2000    0.054    0.000    0.054    0.000 {built-in method ones_like}\n",
       "    20300    0.052    0.000    0.052    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       "    39900    0.051    0.000    0.077    0.000 batchnorm.py:241(_check_input_dim)\n",
       "    20000    0.051    0.000    0.051    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
       "    39900    0.049    0.000    0.080    0.000 __init__.py:461(__get__)\n",
       "     1400    0.042    0.000    0.042    0.000 {built-in method posix.read}\n",
       "    64284    0.037    0.000    0.037    0.000 {method 'append' of 'list' objects}\n",
       "    72173    0.036    0.000    0.037    0.000 {built-in method builtins.isinstance}\n",
       "      100    0.034    0.000    0.034    0.000 {method 'poll' of 'select.poll' objects}\n",
       "        6    0.034    0.006    0.034    0.006 {built-in method _pickle.load}\n",
       "    75821    0.031    0.000    0.031    0.000 {method 'get' of 'dict' objects}\n",
       "    39900    0.031    0.000    0.031    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
       "     2000    0.031    0.000    0.049    0.000 optimizer.py:176(add_param_group)\n",
       "    44044    0.028    0.000    0.028    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "     2100    0.024    0.000    0.024    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       "     2000    0.022    0.000    0.084    0.000 optimizer.py:32(__init__)\n",
       "        1    0.021    0.021    0.021    0.021 {built-in method numpy.core.multiarray.concatenate}\n",
       "     2068    0.021    0.000    0.134    0.000 module.py:77(_construct)\n",
       "     2000    0.019    0.000   11.699    0.006 Attack_Foolbox_ResNet20.py:104(predict)\n",
       "     2000    0.017    0.000   12.411    0.006 tensor.py:90(backward)\n",
       "     2000    0.016    0.000    0.076    0.000 __init__.py:20(_make_grads)\n",
       "     2100    0.016    0.000    0.016    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
       "     2000    0.015    0.000   12.394    0.006 __init__.py:38(backward)\n",
       "     2000    0.015    0.000    0.099    0.000 sgd.py:51(__init__)\n",
       "     4069    0.012    0.000    0.012    0.000 {built-in method torch._C._log_api_usage_once}\n",
       "     2000    0.012    0.000    0.080    0.000 functional.py:1770(nll_loss)\n",
       "      800    0.011    0.000    0.011    0.000 {built-in method posix.write}\n",
       "     8146    0.010    0.000    0.010    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "     2000    0.010    0.000    0.163    0.000 loss.py:914(forward)\n",
       "      200    0.010    0.000    0.010    0.000 {method 'recvmsg' of '_socket.socket' objects}\n",
       "      101    0.010    0.000    0.018    0.000 sampler.py:198(__iter__)\n",
       "     2100    0.010    0.000    0.131    0.000 functional.py:1354(linear)\n",
       "     2100    0.009    0.000    0.143    0.000 linear.py:86(forward)\n",
       "     3240    0.009    0.000    0.019    0.000 {built-in method builtins.hasattr}\n",
       "       12    0.008    0.001    0.008    0.001 {built-in method io.open}\n",
       "     2000    0.008    0.000    0.150    0.000 functional.py:1950(cross_entropy)\n",
       "     2058    0.008    0.000    0.026    0.000 module.py:105(register_buffer)\n",
       "      416    0.007    0.000    0.007    0.000 {built-in method tensor}\n",
       "      200    0.007    0.000    0.007    0.000 {method 'connect' of '_socket.socket' objects}\n",
       "     2001    0.007    0.000    0.214    0.000 loss.py:909(__init__)\n",
       "     2100    0.007    0.000    0.007    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
       "     2000    0.007    0.000    0.015    0.000 grad_mode.py:88(__exit__)\n",
       "    10040    0.006    0.000    0.006    0.000 {method 'setdefault' of 'dict' objects}\n",
       "     2001    0.006    0.000    0.196    0.000 loss.py:18(__init__)\n",
       "      100    0.006    0.000    0.195    0.002 {built-in method _pickle.loads}\n",
       "     2001    0.006    0.000    0.164    0.000 loss.py:9(__init__)\n",
       "     2131    0.006    0.000    0.009    0.000 grad_mode.py:137(__init__)\n",
       "     2100    0.006    0.000    0.062    0.000 pooling.py:549(forward)\n",
       "      400    0.005    0.000    0.014    0.000 hmac.py:26(__init__)\n",
       "     1400    0.005    0.000    0.049    0.000 connection.py:374(_recv)\n",
       "       67    0.005    0.000    0.012    0.000 module.py:718(_load_from_state_dict)\n",
       "     2000    0.005    0.000    0.008    0.000 grad_mode.py:84(__enter__)\n",
       "     2068    0.005    0.000    0.152    0.000 module.py:71(__init__)\n",
       "      800    0.005    0.000    0.005    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "      200    0.004    0.000    0.004    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "      200    0.004    0.000    0.005    0.000 reductions.py:266(storage_from_cache)\n",
       "      400    0.004    0.000    0.004    0.000 socket.py:139(__init__)\n",
       "     2000    0.004    0.000    0.062    0.000 functional.py:1296(log_softmax)\n",
       "      100    0.004    0.000    0.051    0.001 connection.py:253(poll)\n",
       "     9217    0.004    0.000    0.004    0.000 {method 'startswith' of 'str' objects}\n",
       "       20    0.004    0.000    0.004    0.000 {built-in method posix.stat}\n",
       "     4262    0.004    0.000    0.004    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "      200    0.003    0.000    0.018    0.000 connection.py:607(SocketClient)\n",
       "      600    0.003    0.000    0.017    0.000 connection.py:181(send_bytes)\n",
       "      200    0.003    0.000    0.179    0.001 reductions.py:273(rebuild_storage_fd)\n",
       "      700    0.003    0.000    0.054    0.000 connection.py:406(_recv_bytes)\n",
       "      100    0.003    0.000    0.038    0.000 selectors.py:365(select)\n",
       "     2161    0.003    0.000    0.003    0.000 {method 'format' of 'str' objects}\n",
       "      397    0.003    0.000    0.003    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
       "     2000    0.003    0.000    0.003    0.000 optimizer.py:159(zero_grad)\n",
       "      200    0.003    0.000    0.137    0.001 resource_sharer.py:82(get_connection)\n",
       "     2000    0.003    0.000    0.004    0.000 tensor.py:392(__hash__)\n",
       "     2021    0.003    0.000    0.003    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "      200    0.003    0.000    0.067    0.000 connection.py:729(answer_challenge)\n",
       "      700    0.003    0.000    0.058    0.000 connection.py:208(recv_bytes)\n",
       "      800    0.003    0.000    0.016    0.000 connection.py:390(_send_bytes)\n",
       "      200    0.003    0.000    0.014    0.000 reduction.py:149(recvfds)\n",
       "      100    0.003    0.000    0.003    0.000 {built-in method _new_shared_fd}\n",
       "      127    0.003    0.000    0.003    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "      800    0.003    0.000    0.003    0.000 {built-in method _hashlib.new}\n",
       "       21    0.002    0.000    0.002    0.000 {method 'normal_' of 'torch._C._TensorBase' objects}\n",
       "     4262    0.002    0.000    0.002    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "      414    0.002    0.000    0.002    0.000 {built-in method posix.close}\n",
       "      178    0.002    0.000    0.002    0.000 {method '_set_from_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "      100    0.002    0.000    0.254    0.003 queues.py:91(get)\n",
       "        1    0.002    0.002    0.002    0.002 {built-in method builtins.compile}\n",
       "      200    0.002    0.000    0.032    0.000 connection.py:716(deliver_challenge)\n",
       "      200    0.002    0.000    0.004    0.000 reduction.py:38(__init__)\n",
       "      397    0.002    0.000    0.012    0.000 _utils.py:128(_rebuild_tensor)\n",
       "      100    0.002    0.000    0.046    0.000 connection.py:897(wait)\n",
       "      101    0.002    0.000    1.546    0.015 dataloader.py:775(__next__)\n",
       "      400    0.002    0.000    0.002    0.000 {built-in method posix.fstat}\n",
       "      200    0.002    0.000    0.120    0.001 connection.py:478(Client)\n",
       "      197    0.002    0.000    0.007    0.000 serialization.py:93(_cuda_deserialize)\n",
       "      200    0.002    0.000    0.160    0.001 resource_sharer.py:55(detach)\n",
       "      800    0.002    0.000    0.013    0.000 connection.py:365(_send)\n",
       "     2000    0.002    0.000    0.002    0.000 _reduction.py:6(get_enum)\n",
       "      200    0.002    0.000    0.019    0.000 reduction.py:179(recv_handle)\n",
       "      104    0.002    0.000    0.009    0.000 queues.py:80(put)\n",
       "      113    0.002    0.000    0.002    0.000 {method 'release' of '_thread.lock' objects}\n",
       "       36    0.002    0.000    0.002    0.000 socket.py:342(send)\n",
       "      108    0.001    0.000    0.029    0.000 dataloader.py:823(_try_put_index)\n",
       "      200    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
       "     2027    0.001    0.000    0.001    0.000 {built-in method builtins.id}\n",
       "       20    0.001    0.000    0.003    0.000 synchronize.py:50(__init__)\n",
       "        7    0.001    0.000    0.336    0.048 utils.py:24(calculate_md5)\n",
       "        1    0.001    0.001    0.014    0.014 {method 'load' of '_pickle.Unpickler' objects}\n",
       "      800    0.001    0.000    0.005    0.000 hmac.py:52(<lambda>)\n",
       "      200    0.001    0.000    0.006    0.000 reduction.py:48(dumps)\n",
       "     2000    0.001    0.000    0.001    0.000 {method 'isdisjoint' of 'set' objects}\n",
       "      200    0.001    0.000    0.010    0.000 reductions.py:79(rebuild_tensor)\n",
       "     2069    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
       "     1400    0.001    0.000    0.001    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "      197    0.001    0.000    0.009    0.000 serialization.py:520(persistent_load)\n",
       "     1900    0.001    0.000    0.001    0.000 connection.py:134(_check_closed)\n",
       "      800    0.001    0.000    0.004    0.000 hashlib.py:139(__hash_new)\n",
       "      100    0.001    0.000    0.003    0.000 selectors.py:233(register)\n",
       "      210    0.001    0.000    0.001    0.000 connection.py:117(__init__)\n",
       "      200    0.001    0.000    0.012    0.000 connection.py:202(send)\n",
       "      100    0.001    0.000    0.001    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
       "      400    0.001    0.000    0.006    0.000 hmac.py:108(_current)\n",
       "        2    0.001    0.001    0.002    0.001 reductions.py:53(free_dead_references)\n",
       "      108    0.001    0.000    0.003    0.000 threading.py:334(notify)\n",
       "      700    0.001    0.000    0.001    0.000 {built-in method _struct.unpack}\n",
       "      200    0.001    0.000    0.001    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
       "      400    0.001    0.000    0.015    0.000 hmac.py:133(new)\n",
       "      200    0.001    0.000    0.001    0.000 {built-in method posix.urandom}\n",
       "      197    0.001    0.000    0.003    0.000 serialization.py:68(validate_cuda_device)\n",
       "      100    0.001    0.000    0.002    0.000 selectors.py:346(__init__)\n",
       "      208    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
       "      200    0.001    0.000    0.001    0.000 socket.py:419(detach)\n",
       "     67/1    0.001    0.000    0.005    0.005 module.py:206(_apply)\n",
       "      120    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "      200    0.001    0.000    0.003    0.000 reductions.py:48(__setitem__)\n",
       "      400    0.001    0.000    0.001    0.000 connection.py:95(address_type)\n",
       "      400    0.001    0.000    0.007    0.000 hmac.py:117(digest)\n",
       "      200    0.001    0.000    0.001    0.000 reductions.py:26(__init__)\n",
       "      400    0.001    0.000    0.003    0.000 reductions.py:258(fd_id)\n",
       "      395    0.001    0.000    0.001    0.000 __init__.py:62(is_available)\n",
       "     1400    0.001    0.000    0.001    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "      800    0.001    0.000    0.001    0.000 {method 'translate' of 'bytes' objects}\n",
       "        4    0.001    0.000    1.856    0.464 popen_fork.py:63(_launch)\n",
       "      236    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "      100    0.001    0.000    0.047    0.000 connection.py:413(_poll)\n",
       "      800    0.001    0.000    0.001    0.000 {built-in method _struct.pack}\n",
       "      400    0.001    0.000    0.001    0.000 socket.py:151(__exit__)\n",
       "      200    0.001    0.000    0.002    0.000 socket.py:454(fromfd)\n",
       "      100    0.001    0.000    0.025    0.000 dataloader.py:842(_process_data)\n",
       "      100    0.001    0.000    0.255    0.003 dataloader.py:742(_get_data)\n",
       "      100    0.001    0.000    0.001    0.000 selectors.py:208(__init__)\n",
       "      100    0.001    0.000    0.001    0.000 selectors.py:20(_fileobj_to_fd)\n",
       "      800    0.001    0.000    0.001    0.000 connection.py:138(_check_readable)\n",
       "      719    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
       "      269    0.001    0.000    0.020    0.000 {built-in method builtins.next}\n",
       "       19    0.001    0.000    0.005    0.000 batchnorm.py:19(__init__)\n",
       "      100    0.001    0.000    0.255    0.003 dataloader.py:711(_try_get_data)\n",
       "      100    0.000    0.000    0.004    0.000 selectors.py:350(register)\n",
       "      204    0.000    0.000    0.002    0.000 connection.py:173(close)\n",
       "        1    0.000    0.000    1.873    1.873 dataloader.py:635(__init__)\n",
       "       21    0.000    0.000    0.007    0.000 conv.py:18(__init__)\n",
       "      200    0.000    0.000    0.000    0.000 {built-in method _socket.dup}\n",
       "      204    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "      275    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "      100    0.000    0.000    0.002    0.000 fromnumeric.py:943(argmax)\n",
       "      800    0.000    0.000    0.000    0.000 connection.py:142(_check_writable)\n",
       "      400    0.000    0.000    0.001    0.000 hmac.py:90(update)\n",
       "      400    0.000    0.000    0.000    0.000 {method 'ljust' of 'bytes' objects}\n",
       "      400    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "      300    0.000    0.000    0.001    0.000 connection.py:168(fileno)\n",
       "      200    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "       23    0.000    0.000    0.001    0.000 init.py:202(_calculate_fan_in_and_fan_out)\n",
       "      200    0.000    0.000    0.001    0.000 socket.py:413(close)\n",
       "      197    0.000    0.000    0.001    0.000 __init__.py:240(__enter__)\n",
       "      300    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
       "      197    0.000    0.000    0.007    0.000 serialization.py:117(default_restore_location)\n",
       "      239    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:62(__init__)\n",
       "   309/68    0.000    0.000    0.000    0.000 module.py:1015(named_modules)\n",
       "      188    0.000    0.000    0.059    0.000 utils.py:27(<lambda>)\n",
       "        1    0.000    0.000    0.020    0.020 nagpreresnet_learned_v2_vo0.py:114(__init__)\n",
       "      236    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
       "      200    0.000    0.000    0.003    0.000 connection.py:262(__exit__)\n",
       "        1    0.000    0.000   70.372   70.372 py3compat.py:184(execfile)\n",
       "      197    0.000    0.000    0.001    0.000 _utils.py:5(_get_device_index)\n",
       "      160    0.000    0.000    0.001    0.000 random.py:255(choice)\n",
       "     67/1    0.000    0.000    0.012    0.012 module.py:822(load)\n",
       "      206    0.000    0.000    0.002    0.000 connection.py:360(_close)\n",
       "      200    0.000    0.000    0.000    0.000 {method 'setblocking' of '_socket.socket' objects}\n",
       "      300    0.000    0.000    0.001    0.000 reductions.py:32(expired)\n",
       "      220    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
       "      100    0.000    0.000    0.001    0.000 <string>:12(__new__)\n",
       "      100    0.000    0.000    0.002    0.000 fromnumeric.py:50(_wrapfunc)\n",
       "      394    0.000    0.000    0.001    0.000 serialization.py:509(maybe_decode_ascii)\n",
       "        1    0.000    0.000    0.394    0.394 cifar.py:55(__init__)\n",
       "        1    0.000    0.000    0.022    0.022 serialization.py:392(_load)\n",
       "      197    0.000    0.000    0.004    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:268(close)\n",
       "      160    0.000    0.000    0.001    0.000 random.py:223(_randbelow)\n",
       "       36    0.000    0.000    0.002    0.000 iostream.py:197(schedule)\n",
       "      120    0.000    0.000    0.001    0.000 threading.py:239(__enter__)\n",
       "      266    0.000    0.000    0.000    0.000 module.py:968(named_children)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
       "       76    0.000    0.000    0.000    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "      266    0.000    0.000    0.001    0.000 module.py:959(children)\n",
       "      120    0.000    0.000    0.001    0.000 threading.py:242(__exit__)\n",
       "      126    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5601a452be00}\n",
       "      592    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "        5    0.000    0.000    0.004    0.001 context.py:99(Queue)\n",
       "      131    0.000    0.000    0.001    0.000 grad_mode.py:41(__exit__)\n",
       "      100    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
       "       91    0.000    0.000    0.001    0.000 module.py:143(register_parameter)\n",
       "      197    0.000    0.000    0.001    0.000 __init__.py:357(device_count)\n",
       "      200    0.000    0.000    0.000    0.000 {built-in method _socket.CMSG_SPACE}\n",
       "        5    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "       20    0.000    0.000    0.001    0.000 tempfile.py:157(__next__)\n",
       "      200    0.000    0.000    0.000    0.000 {method 'frombytes' of 'array.array' objects}\n",
       "      494    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "      197    0.000    0.000    0.001    0.000 __init__.py:236(__init__)\n",
       "      200    0.000    0.000    0.000    0.000 process.py:170(authkey)\n",
       "      400    0.000    0.000    0.000    0.000 socket.py:148(__enter__)\n",
       "      100    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method ones}\n",
       "        8    0.000    0.000    0.004    0.001 iostream.py:336(flush)\n",
       "      200    0.000    0.000    0.000    0.000 connection.py:83(_validate_family)\n",
       "      481    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "       67    0.000    0.000    0.000    0.000 module.py:755(<dictcomp>)\n",
       "      100    0.000    0.000    0.001    0.000 selectors.py:214(_fileobj_lookup)\n",
       "      108    0.000    0.000    0.019    0.000 dataloader.py:317(_next_index)\n",
       "      131    0.000    0.000    0.000    0.000 grad_mode.py:37(__enter__)\n",
       "      395    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "      120    0.000    0.000    0.000    0.000 threading.py:254(_is_owned)\n",
       "      536    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "       12    0.000    0.000    0.000    0.000 util.py:151(__init__)\n",
       "       57    0.000    0.000    0.000    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "      210    0.000    0.000    0.000    0.000 reductions.py:35(__del__)\n",
       "      120    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "        9    0.000    0.000    0.014    0.002 nagpreresnet_learned_v2_vo0.py:28(__init__)\n",
       "        4    0.000    0.000    0.002    0.001 queues.py:155(_start_thread)\n",
       "        1    0.000    0.000   70.374   70.374 interactiveshell.py:2673(safe_execfile)\n",
       "      203    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
       "      300    0.000    0.000    0.000    0.000 {built-in method _expired}\n",
       "      100    0.000    0.000    0.001    0.000 selectors.py:201(__exit__)\n",
       "       25    0.000    0.000    0.000    0.000 weakref.py:165(__setitem__)\n",
       "        5    0.000    0.000    0.004    0.001 queues.py:36(__init__)\n",
       "        4    0.000    0.000    1.861    0.465 process.py:95(start)\n",
       "      105    0.000    0.000    0.000    0.000 abc.py:180(__instancecheck__)\n",
       "       17    0.000    0.000    0.000    0.000 threading.py:215(__init__)\n",
       "      100    0.000    0.000    0.000    0.000 connection.py:913(<listcomp>)\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method zeros}\n",
       "      200    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
       "       19    0.000    0.000    0.000    0.000 {method '_set_from_file' of 'torch._C.CudaLongStorageBase' objects}\n",
       "       22    0.000    0.000    0.003    0.000 init.py:287(kaiming_uniform_)\n",
       "      200    0.000    0.000    0.000    0.000 {function socket.detach at 0x7f3962bf2ae8}\n",
       "      127    0.000    0.000    0.003    0.000 module.py:311(<lambda>)\n",
       "       44    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
       "     67/1    0.000    0.000    0.001    0.001 module.py:1053(train)\n",
       "      201    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
       "      210    0.000    0.000    0.000    0.000 {built-in method _free_weak_ref}\n",
       "      207    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
       "       12    0.000    0.000    0.005    0.000 threading.py:533(wait)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "       21    0.000    0.000    0.007    0.000 conv.py:321(__init__)\n",
       "       19    0.000    0.000    0.001    0.000 argparse.py:1307(add_argument)\n",
       "      197    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}\n",
       "      105    0.000    0.000    0.001    0.000 utils.py:6(parse)\n",
       "      210    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
       "      100    0.000    0.000    0.000    0.000 {built-in method select.poll}\n",
       "       21    0.000    0.000    0.000    0.000 posixpath.py:75(join)\n",
       "       70    0.000    0.000    0.000    0.000 module.py:210(compute_should_use_set_data)\n",
       "      220    0.000    0.000    0.000    0.000 process.py:35(current_process)\n",
       "      156    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)\n",
       "       70    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
       "      125    0.000    0.000    0.000    0.000 module.py:594(remove_from)\n",
       "       12    0.000    0.000    0.004    0.000 threading.py:263(wait)\n",
       "      264    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "        4    0.000    0.000    1.861    0.465 context.py:274(_Popen)\n",
       "        9    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "      100    0.000    0.000    0.000    0.000 {method '_weak_ref' of 'torch._C.FloatStorageBase' objects}\n",
       "       10    0.000    0.000    1.263    0.126 popen_fork.py:24(poll)\n",
       "       21    0.000    0.000    0.003    0.000 conv.py:48(reset_parameters)\n",
       "       19    0.000    0.000    0.000    0.000 batchnorm.py:43(reset_running_stats)\n",
       "      200    0.000    0.000    0.000    0.000 connection.py:259(__enter__)\n",
       "      230    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
       "       70    0.000    0.000    0.000    0.000 {built-in method _has_compatible_shallow_copy_type}\n",
       "        2    0.000    0.000    1.264    0.632 dataloader.py:872(_shutdown_workers)\n",
       "        4    0.000    0.000    0.000    0.000 process.py:71(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:157(__init__)\n",
       "       18    0.000    0.000    0.002    0.000 iostream.py:384(write)\n",
       "       11    0.000    0.000    0.003    0.000 context.py:64(Lock)\n",
       "       20    0.000    0.000    0.001    0.000 tempfile.py:160(<listcomp>)\n",
       "      197    0.000    0.000    0.000    0.000 __init__.py:248(__exit__)\n",
       "        1    0.000    0.000    0.002    0.002 cifar.py:97(_load_meta)\n",
       "        4    0.000    0.000    1.861    0.465 popen_fork.py:16(__init__)\n",
       "       19    0.000    0.000    0.001    0.000 batchnorm.py:49(reset_parameters)\n",
       "       25    0.000    0.000    0.001    0.000 util.py:136(register_after_fork)\n",
       "       70    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "       20    0.000    0.000    0.002    0.000 synchronize.py:114(_make_name)\n",
       "       22    0.000    0.000    0.000    0.000 init.py:32(calculate_gain)\n",
       "      2/1    0.000    0.000   70.374   70.374 {built-in method builtins.exec}\n",
       "      197    0.000    0.000    0.000    0.000 __init__.py:164(_lazy_init)\n",
       "       19    0.000    0.000    0.005    0.000 batchnorm.py:87(_load_from_state_dict)\n",
       "      197    0.000    0.000    0.000    0.000 serialization.py:63(_cpu_deserialize)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:757(__init__)\n",
       "      101    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "      100    0.000    0.000    0.000    0.000 {method '_weak_ref' of 'torch._C.LongStorageBase' objects}\n",
       "        5    0.000    0.000    0.000    0.000 connection.py:501(Pipe)\n",
       "        4    0.000    0.000    0.004    0.001 util.py:395(_flush_std_streams)\n",
       "      178    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
       "        7    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
       "       44    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
       "       19    0.000    0.000    0.000    0.000 init.py:22(_no_grad_fill_)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "        4    0.000    0.000    1.861    0.465 context.py:221(_Popen)\n",
       "       12    0.000    0.000    0.000    0.000 threading.py:498(__init__)\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)\n",
       "        1    0.000    0.000    1.873    1.873 dataloader.py:274(__iter__)\n",
       "       25    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "       22    0.000    0.000    0.000    0.000 weakref.py:109(remove)\n",
       "       32    0.000    0.000    0.000    0.000 Attack_Foolbox_ResNet20.py:47(<genexpr>)\n",
       "       36    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
       "       18    0.000    0.000    0.006    0.000 nagpreresnet_learned_v2_vo0.py:19(conv3x3)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1775(_parse_known_args)\n",
       "      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "       25    0.000    0.000    0.000    0.000 os.py:664(__getitem__)\n",
       "       34    0.000    0.000    0.000    0.000 {built-in method _new_with_weak_ptr}\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:466(find)\n",
       "      100    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "        1    0.000    0.000    0.023    0.023 serialization.py:305(load)\n",
       "       29    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
       "       18    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
       "        3    0.000    0.000    0.015    0.005 nagpreresnet_learned_v2_vo0.py:149(_make_layer)\n",
       "        8    0.000    0.000    0.001    0.000 util.py:167(__call__)\n",
       "       22    0.000    0.000    0.001    0.000 init.py:277(_calculate_correct_fan)\n",
       "       19    0.000    0.000    0.000    0.000 init.py:27(_no_grad_zero_)\n",
       "       20    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
       "        5    0.000    0.000    0.001    0.000 context.py:84(BoundedSemaphore)\n",
       "        4    0.000    0.000    0.000    0.000 process.py:52(_cleanup)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "       51    0.000    0.000    0.000    0.000 re.py:286(_compile)\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:198(__enter__)\n",
       "       25    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "      110    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
       "        4    0.000    0.000    0.002    0.000 threading.py:828(start)\n",
       "       48    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
       "       29    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
       "       68    0.000    0.000    0.000    0.000 module.py:988(modules)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "        4    0.000    0.000    1.263    0.316 popen_fork.py:43(wait)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:154(dirname)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:580(_format_args)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "       11    0.000    0.000    0.002    0.000 synchronize.py:161(__init__)\n",
       "        4    0.000    0.000    1.263    0.316 process.py:118(join)\n",
       "       12    0.000    0.000    0.000    0.000 threading.py:251(_acquire_restore)\n",
       "        4    0.000    0.000    0.000    0.000 queues.py:147(cancel_join_thread)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method empty}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
       "        7    0.000    0.000    0.336    0.048 utils.py:32(check_md5)\n",
       "        5    0.000    0.000    0.000    0.000 container.py:46(__init__)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:1822(take_action)\n",
       "       27    0.000    0.000    0.000    0.000 os.py:742(encode)\n",
       "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._error_if_any_worker_fails}\n",
       "        7    0.000    0.000    0.339    0.048 utils.py:36(check_integrity)\n",
       "       70    0.000    0.000    0.000    0.000 __future__.py:18(get_overwrite_module_params_on_conversion)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:2352(_get_formatter)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1740(parse_known_args)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "       45    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:120(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1555(_add_action)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:1843(consume_optional)\n",
       "       52    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
       "        1    0.000    0.000    0.338    0.338 cifar.py:135(_check_integrity)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "        8    0.000    0.000    0.004    0.000 genericpath.py:27(isfile)\n",
       "       10    0.000    0.000    0.001    0.000 activation.py:89(__init__)\n",
       "       18    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "       67    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}\n",
       "       53    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
       "       19    0.000    0.000    0.000    0.000 init.py:123(ones_)\n",
       "       45    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "       37    0.000    0.000    0.000    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:345(set)\n",
       "        3    0.000    0.000    0.000    0.000 signal_handling.py:63(handler)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "       41    0.000    0.000    0.000    0.000 re.py:231(compile)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "       43    0.000    0.000    0.000    0.000 {method 'islower' of 'str' objects}\n",
       "       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "        4    0.000    0.000    0.000    0.000 queues.py:131(close)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1713(_add_action)\n",
       "        4    0.000    0.000    0.000    0.000 queues.py:196(_finalize_close)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:338(normpath)\n",
       "    14/13    0.000    0.000    0.000    0.000 dataloader.py:267(__setattr__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:301(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 init.py:137(zeros_)\n",
       "        1    0.000    0.000    0.013    0.013 module.py:794(load_state_dict)\n",
       "        1    0.000    0.000   70.374   70.374 <string>:1(<module>)\n",
       "       26    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
       "        8    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
       "        5    0.000    0.000    0.000    0.000 dataloader.py:703(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        4    0.000    0.000    0.000    0.000 context.py:79(Semaphore)\n",
       "       11    0.000    0.000    0.000    0.000 module.py:182(add_module)\n",
       "        4    0.000    0.000    0.000    0.000 util.py:191(cancel)\n",
       "        7    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "       32    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "       29    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:68(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 tarfile.py:1411(__init__)\n",
       "       12    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
       "       27    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "       41    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
       "        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_md5}\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "       10    0.000    0.000    0.000    0.000 re.py:169(match)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:287(notify_all)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
       "        1    0.000    0.000    0.021    0.021 shape_base.py:182(vstack)\n",
       "       18    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
       "       20    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "       12    0.000    0.000    0.000    0.000 threading.py:248(_release_save)\n",
       "       29    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 threading.py:1230(current_thread)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
       "        1    0.000    0.000    0.002    0.002 tarfile.py:2276(next)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:572(dgettext)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "        5    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)\n",
       "       18    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
       "        4    0.000    0.000    0.000    0.000 dataloader.py:849(_shutdown_worker)\n",
       "       20    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "        1    0.000    0.000    0.002    0.002 serialization.py:455(legacy_load)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
       "       21    0.000    0.000    0.000    0.000 context.py:186(get_context)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:506(translation)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:79(reset_parameters)\n",
       "        6    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.LongStorageBase' objects}\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:257(_EndRecData)\n",
       "        1    0.000    0.000    0.002    0.002 tarfile.py:1522(open)\n",
       "        1    0.000    0.000    0.000    0.000 shape_base.py:63(atleast_2d)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:61(__iter__)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "       11    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
       "        1    0.000    0.000    0.020    0.020 nagpreresnet_learned_v2_vo0.py:188(nagpreresnet_learned_v2_vo0)\n",
       "        1    0.000    0.000    0.001    0.001 Attack_Foolbox_ResNet20.py:97(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
       "       10    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:376(abspath)\n",
       "        9    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "        4    0.000    0.000    0.000    0.000 synchronize.py:125(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 vision.py:9(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 process.py:83(<genexpr>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "       10    0.000    0.000    0.000    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method _imp.lock_held}\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:155(_is_compressed_file)\n",
       "        1    0.000    0.000    0.000    0.000 context.py:74(Condition)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:89(Event)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "        1    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "       10    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
       "        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:539(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:179(_check_seekable)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "        8    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:1120(daemon)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "        3    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:64(isabs)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "        6    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:108(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:132(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:182(__init__)\n",
       "        1    0.000    0.000    0.002    0.002 tarfile.py:1087(fromtarfile)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:495(asanyarray)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1733(parse_args)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}\n",
       "        1    0.000    0.000    0.001    0.001 synchronize.py:334(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:56(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:239(multiprocessing_context)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:12(_no_grad_uniform_)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:198(is_zipfile)\n",
       "        1    0.000    0.000    0.002    0.002 tarfile.py:1613(taropen)\n",
       "        4    0.000    0.000    0.000    0.000 process.py:162(daemon)\n",
       "        3    0.000    0.000    0.000    0.000 gettext.py:611(gettext)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:163(_should_read_directly)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
       "        1    0.000    0.000    0.000    0.000 shape_base.py:234(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 posixpath.py:144(basename)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 vision.py:55(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 dataloader.py:280(_auto_collation)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:284(_index_sampler)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:74(uniform_)\n",
       "        1    0.000    0.000    0.001    0.001 module.py:1073(eval)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:190(_check_zipfile)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 Attack_Foolbox_ResNet20.py:96(PytorchModel)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        4    0.000    0.000    0.000    0.000 process.py:190(ident)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1642(identity)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 attack_toolbox.py:23(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:58(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:235(multiprocessing_context)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:925(__del__)\n",
       "        1    0.000    0.000    0.005    0.005 module.py:297(cuda)\n",
       "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:526(get)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.999-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.95-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.9-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.7-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.5-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.3-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.1-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.01-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.001-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_vo020-basicblock-eta-0.0001-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_learned_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_learned_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_learned_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_learned_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_learned_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_learned_v2_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_learned_v2_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_learned_v2_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_learned_v2_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v2_vo020-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_learned_v2_vo0\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method ifgsm --epsilon 0.031 --gpu-id 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
