{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5055\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  4998\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5037\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5025\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5065\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5055\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5030\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5005\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5034\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4949\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5022\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5050\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5018\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5036\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5048\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5091\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5048\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5039\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5086\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  4987\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5068\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5062\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5095\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5050\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5064\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5037\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5067\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5085\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5070\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5056\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5093\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5122\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5122\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5111\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5073\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5118\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5146\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5080\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5138\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5093\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5094\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5120\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5083\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5025\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5139\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5077\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5134\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5077\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5092\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5084\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5062\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5123\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5094\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5089\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5038\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5047\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5064\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  4764\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5047\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5130\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\n",
      "Number of correctly classified images:  5159\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\n",
      "Number of correctly classified images:  5138\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\n",
      "Number of correctly classified images:  5051\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\n",
      "Number of correctly classified images:  5098\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " ==> creating model 'nagpreresnet_learned_v2'\n",
      "==> Resuming from checkpoint..\n",
      "==> Load the clean image\n",
      "Batch size of the test set:  100\n",
      "/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\n",
      "Number of correctly classified images:  5122\n",
      "[(10000, 3, 32, 32), (10000, 3, 32, 32), (10000, 3, 32, 32), (10000,), (10000,)]\n",
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         410744 function calls (393702 primitive calls) in 52.286 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "    20300   29.446    0.001   29.446    0.001 {method 'cpu' of 'torch._C._TensorBase' objects}\n",
       "        6   15.148    2.525   15.148    2.525 {built-in method numpy.core.multiarray.array}\n",
       "        4    2.102    0.526    2.102    0.526 {built-in method posix.fork}\n",
       "       10    1.405    0.141    1.405    0.141 {built-in method posix.waitpid}\n",
       "      100    0.785    0.008    0.785    0.008 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
       "        1    0.602    0.602   52.281   52.281 Attack_Foolbox_ResNet20.py:4(<module>)\n",
       "     4600    0.419    0.000    0.419    0.000 {built-in method conv2d}\n",
       "     1781    0.333    0.000    0.333    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "     1800    0.271    0.000    1.319    0.001 nagpreresnet_learned_v2.py:39(forward)\n",
       "     3800    0.235    0.000    0.235    0.000 {built-in method batch_norm}\n",
       "      192    0.180    0.001    0.180    0.001 {method 'read' of '_io.BufferedReader' objects}\n",
       "16100/300    0.146    0.000    1.496    0.005 module.py:537(__call__)\n",
       "     3800    0.107    0.000    0.107    0.000 {built-in method relu_}\n",
       "    20300    0.069    0.000    0.069    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
       "    20000    0.065    0.000    0.065    0.000 {method 'detach' of 'torch._C._TensorBase' objects}\n",
       "    40760    0.059    0.000    0.060    0.000 module.py:577(__getattr__)\n",
       "      427    0.058    0.000    0.058    0.000 {method 'cuda' of 'torch._C._TensorBase' objects}\n",
       "        6    0.046    0.008    0.046    0.008 {built-in method _pickle.load}\n",
       "     1400    0.044    0.000    0.044    0.000 {built-in method posix.read}\n",
       "    60384    0.042    0.000    0.042    0.000 {method 'append' of 'list' objects}\n",
       "      100    0.039    0.000    0.039    0.000 {method 'poll' of 'select.poll' objects}\n",
       "     3800    0.036    0.000    0.324    0.000 batchnorm.py:58(forward)\n",
       "    16100    0.029    0.000    0.029    0.000 {built-in method torch._C._get_tracing_state}\n",
       "     4600    0.028    0.000    0.450    0.000 conv.py:332(conv2d_forward)\n",
       "        1    0.024    0.024    0.024    0.024 {built-in method numpy.core.multiarray.concatenate}\n",
       "    33667    0.021    0.000    0.021    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
       "32785/32784    0.019    0.000    0.019    0.000 {built-in method builtins.len}\n",
       "     3800    0.017    0.000    0.262    0.000 functional.py:1629(batch_norm)\n",
       "     4600    0.016    0.000    0.472    0.000 conv.py:342(forward)\n",
       "      100    0.015    0.000    1.692    0.017 attack_toolbox.py:86(fgsm)\n",
       "      200    0.014    0.000    0.014    0.000 {built-in method addmm}\n",
       "      101    0.012    0.000    0.022    0.000 sampler.py:198(__iter__)\n",
       " 1400/600    0.012    0.000    1.355    0.002 container.py:90(forward)\n",
       "      800    0.012    0.000    0.012    0.000 {built-in method posix.write}\n",
       "       12    0.011    0.001    0.011    0.001 {built-in method io.open}\n",
       "     2419    0.011    0.000    0.019    0.000 module.py:593(__setattr__)\n",
       "      200    0.011    0.000    1.478    0.007 nagpreresnet_learned_v2.py:165(forward)\n",
       "      200    0.011    0.000    0.011    0.000 {built-in method clamp}\n",
       "      200    0.010    0.000    0.010    0.000 {method 'recvmsg' of '_socket.socket' objects}\n",
       "      416    0.009    0.000    0.009    0.000 {built-in method tensor}\n",
       "     3800    0.009    0.000    0.124    0.000 activation.py:93(forward)\n",
       "      200    0.008    0.000    0.008    0.000 {method 'connect' of '_socket.socket' objects}\n",
       "     3800    0.008    0.000    0.115    0.000 functional.py:903(relu)\n",
       "      200    0.007    0.000    0.007    0.000 {built-in method torch._C._nn.avg_pool2d}\n",
       "      400    0.007    0.000    0.017    0.000 hmac.py:26(__init__)\n",
       "       67    0.007    0.000    0.015    0.000 module.py:718(_load_from_state_dict)\n",
       "      100    0.007    0.000    0.207    0.002 {built-in method _pickle.loads}\n",
       "     3800    0.006    0.000    0.009    0.000 batchnorm.py:241(_check_input_dim)\n",
       "      197    0.006    0.000    0.006    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "     3800    0.006    0.000    0.009    0.000 __init__.py:461(__get__)\n",
       "     8873    0.006    0.000    0.006    0.000 {built-in method builtins.isinstance}\n",
       "     1400    0.006    0.000    0.052    0.000 connection.py:374(_recv)\n",
       "      100    0.005    0.000    0.007    0.000 fromnumeric.py:50(_wrapfunc)\n",
       "      100    0.005    0.000    0.005    0.000 {built-in method torch._C._nn.nll_loss}\n",
       "       20    0.005    0.000    0.005    0.000 {built-in method posix.stat}\n",
       "      397    0.005    0.000    0.005    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
       "      200    0.005    0.000    0.020    0.000 connection.py:607(SocketClient)\n",
       "     9217    0.004    0.000    0.004    0.000 {method 'startswith' of 'str' objects}\n",
       "      400    0.004    0.000    0.004    0.000 socket.py:139(__init__)\n",
       "     7421    0.004    0.000    0.004    0.000 {method 'get' of 'dict' objects}\n",
       "      100    0.004    0.000    0.004    0.000 {method 'sign_' of 'torch._C._TensorBase' objects}\n",
       "      100    0.004    0.000    0.004    0.000 {method 'log_softmax' of 'torch._C._TensorBase' objects}\n",
       "      200    0.004    0.000    0.190    0.001 reductions.py:273(rebuild_storage_fd)\n",
       "      200    0.004    0.000    0.148    0.001 resource_sharer.py:82(get_connection)\n",
       "      127    0.004    0.000    0.004    0.000 {method 'copy_' of 'torch._C._TensorBase' objects}\n",
       "      178    0.004    0.000    0.004    0.000 {method '_set_from_file' of 'torch._C.CudaFloatStorageBase' objects}\n",
       "      600    0.004    0.000    0.018    0.000 connection.py:181(send_bytes)\n",
       "      200    0.004    0.000    0.074    0.000 connection.py:729(answer_challenge)\n",
       "      700    0.003    0.000    0.057    0.000 connection.py:406(_recv_bytes)\n",
       "      100    0.003    0.000    0.003    0.000 {built-in method ones_like}\n",
       "     3800    0.003    0.000    0.003    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
       "      700    0.003    0.000    0.062    0.000 connection.py:208(recv_bytes)\n",
       "     4144    0.003    0.000    0.003    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
       "       21    0.003    0.000    0.003    0.000 {method 'normal_' of 'torch._C._TensorBase' objects}\n",
       "      800    0.003    0.000    0.018    0.000 connection.py:390(_send_bytes)\n",
       "      200    0.003    0.000    0.014    0.000 reduction.py:149(recvfds)\n",
       "      200    0.003    0.000    0.005    0.000 reduction.py:38(__init__)\n",
       "      197    0.003    0.000    0.009    0.000 serialization.py:93(_cuda_deserialize)\n",
       "      800    0.003    0.000    0.003    0.000 {built-in method _hashlib.new}\n",
       "      168    0.003    0.000    0.015    0.000 module.py:77(_construct)\n",
       "      200    0.003    0.000    0.003    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
       "      100    0.003    0.000    0.003    0.000 {built-in method _new_shared_fd}\n",
       "        1    0.003    0.003    0.003    0.003 {built-in method builtins.compile}\n",
       "      414    0.003    0.000    0.003    0.000 {built-in method posix.close}\n",
       "      100    0.002    0.000    0.268    0.003 queues.py:91(get)\n",
       "      200    0.002    0.000    0.030    0.000 connection.py:716(deliver_challenge)\n",
       "     1340    0.002    0.000    0.004    0.000 {built-in method builtins.hasattr}\n",
       "       23    0.002    0.000    0.002    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
       "      397    0.002    0.000    0.016    0.000 _utils.py:128(_rebuild_tensor)\n",
       "      200    0.002    0.000    0.002    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
       "      100    0.002    0.000    0.050    0.000 connection.py:897(wait)\n",
       "      101    0.002    0.000    1.708    0.017 dataloader.py:775(__next__)\n",
       "      200    0.002    0.000    0.128    0.001 connection.py:478(Client)\n",
       "      400    0.002    0.000    0.002    0.000 {built-in method posix.fstat}\n",
       "      114    0.002    0.000    0.002    0.000 {method 'release' of '_thread.lock' objects}\n",
       "      108    0.002    0.000    0.036    0.000 dataloader.py:823(_try_put_index)\n",
       "      104    0.002    0.000    0.011    0.000 queues.py:80(put)\n",
       "        7    0.002    0.000    0.404    0.058 utils.py:24(calculate_md5)\n",
       "      800    0.002    0.000    0.014    0.000 connection.py:365(_send)\n",
       "       37    0.002    0.000    0.002    0.000 socket.py:342(send)\n",
       "      200    0.002    0.000    0.020    0.000 reduction.py:179(recv_handle)\n",
       "        1    0.002    0.002    0.022    0.022 {method 'load' of '_pickle.Unpickler' objects}\n",
       "      200    0.002    0.000    0.173    0.001 resource_sharer.py:55(detach)\n",
       "      210    0.002    0.000    0.002    0.000 connection.py:117(__init__)\n",
       "      100    0.002    0.000    0.791    0.008 Attack_Foolbox_ResNet20.py:104(predict)\n",
       "      200    0.002    0.000    0.011    0.000 reductions.py:79(rebuild_tensor)\n",
       "      200    0.002    0.000    0.002    0.000 {method 'update' of 'dict' objects}\n",
       "      100    0.002    0.000    0.824    0.008 attack_toolbox.py:26(get_loss)\n",
       "      197    0.002    0.000    0.012    0.000 serialization.py:520(persistent_load)\n",
       "      800    0.002    0.000    0.006    0.000 hmac.py:52(<lambda>)\n",
       "      800    0.001    0.000    0.004    0.000 hashlib.py:139(__hash_new)\n",
       "       20    0.001    0.000    0.004    0.000 synchronize.py:50(__init__)\n",
       "     1900    0.001    0.000    0.001    0.000 connection.py:134(_check_closed)\n",
       "      200    0.001    0.000    0.008    0.000 reduction.py:48(dumps)\n",
       "      100    0.001    0.000    0.001    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
       "      100    0.001    0.000    0.005    0.000 __init__.py:20(_make_grads)\n",
       "     67/1    0.001    0.000    0.007    0.007 module.py:206(_apply)\n",
       "      200    0.001    0.000    0.020    0.000 linear.py:86(forward)\n",
       "      200    0.001    0.000    0.018    0.000 functional.py:1354(linear)\n",
       "     1400    0.001    0.000    0.001    0.000 {method 'write' of '_io.BytesIO' objects}\n",
       "      108    0.001    0.000    0.004    0.000 threading.py:334(notify)\n",
       "      200    0.001    0.000    0.014    0.000 connection.py:202(send)\n",
       "      100    0.001    0.000    0.792    0.008 __init__.py:38(backward)\n",
       "      400    0.001    0.000    0.002    0.000 hmac.py:108(_current)\n",
       "      400    0.001    0.000    0.018    0.000 hmac.py:133(new)\n",
       "      100    0.001    0.000    0.003    0.000 selectors.py:233(register)\n",
       "      700    0.001    0.000    0.001    0.000 {built-in method _struct.unpack}\n",
       "      197    0.001    0.000    0.004    0.000 serialization.py:68(validate_cuda_device)\n",
       "      200    0.001    0.000    0.001    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
       "      100    0.001    0.000    0.793    0.008 tensor.py:90(backward)\n",
       "        2    0.001    0.001    0.002    0.001 reductions.py:53(free_dead_references)\n",
       "      100    0.001    0.000    0.007    0.000 functional.py:1770(nll_loss)\n",
       "      158    0.001    0.000    0.003    0.000 module.py:105(register_buffer)\n",
       "      400    0.001    0.000    0.001    0.000 connection.py:95(address_type)\n",
       "      100    0.001    0.000    0.041    0.000 selectors.py:365(select)\n",
       "      200    0.001    0.000    0.001    0.000 {built-in method posix.urandom}\n",
       "      546    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
       "      169    0.001    0.000    0.001    0.000 {built-in method torch._C._log_api_usage_once}\n",
       "      200    0.001    0.000    0.003    0.000 reductions.py:48(__setitem__)\n",
       "      395    0.001    0.000    0.002    0.000 __init__.py:62(is_available)\n",
       "      400    0.001    0.000    0.003    0.000 reductions.py:258(fd_id)\n",
       "     1400    0.001    0.000    0.001    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
       "      200    0.001    0.000    0.001    0.000 socket.py:419(detach)\n",
       "      400    0.001    0.000    0.004    0.000 hmac.py:117(digest)\n",
       "      208    0.001    0.000    0.001    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
       "      200    0.001    0.000    0.008    0.000 pooling.py:549(forward)\n",
       "      100    0.001    0.000    0.052    0.001 connection.py:253(poll)\n",
       "      200    0.001    0.000    0.001    0.000 reductions.py:26(__init__)\n",
       "      800    0.001    0.000    0.001    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "      800    0.001    0.000    0.001    0.000 {method 'translate' of 'bytes' objects}\n",
       "      120    0.001    0.000    0.001    0.000 {method '__enter__' of '_thread.lock' objects}\n",
       "      800    0.001    0.000    0.001    0.000 {built-in method _struct.pack}\n",
       "      101    0.001    0.000    0.018    0.000 loss.py:909(__init__)\n",
       "      236    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:416(parent)\n",
       "      100    0.001    0.000    0.002    0.000 selectors.py:346(__init__)\n",
       "      101    0.001    0.000    0.016    0.000 loss.py:18(__init__)\n",
       "      719    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
       "       21    0.001    0.000    0.008    0.000 conv.py:18(__init__)\n",
       "      100    0.001    0.000    0.030    0.000 dataloader.py:842(_process_data)\n",
       "      800    0.001    0.000    0.001    0.000 connection.py:138(_check_readable)\n",
       "      101    0.001    0.000    0.013    0.000 loss.py:9(__init__)\n",
       "      100    0.001    0.000    0.012    0.000 functional.py:1950(cross_entropy)\n",
       "        4    0.001    0.000    2.103    0.526 popen_fork.py:63(_launch)\n",
       "       19    0.001    0.000    0.007    0.000 batchnorm.py:19(__init__)\n",
       "      197    0.001    0.000    0.010    0.000 serialization.py:117(default_restore_location)\n",
       "      400    0.001    0.000    0.002    0.000 socket.py:151(__exit__)\n",
       "      100    0.001    0.000    0.013    0.000 loss.py:914(forward)\n",
       "      100    0.001    0.000    0.050    0.001 connection.py:413(_poll)\n",
       "      100    0.001    0.000    0.004    0.000 selectors.py:350(register)\n",
       "      200    0.001    0.000    0.001    0.000 reductions.py:266(storage_from_cache)\n",
       "      200    0.001    0.000    0.002    0.000 socket.py:454(fromfd)\n",
       "      100    0.001    0.000    0.001    0.000 selectors.py:20(_fileobj_to_fd)\n",
       "        1    0.001    0.001    2.124    2.124 dataloader.py:635(__init__)\n",
       "      168    0.001    0.000    0.017    0.000 module.py:71(__init__)\n",
       "      100    0.001    0.000    0.001    0.000 selectors.py:208(__init__)\n",
       "      400    0.001    0.000    0.001    0.000 hmac.py:90(update)\n",
       "      204    0.001    0.000    0.003    0.000 connection.py:173(close)\n",
       "       23    0.001    0.000    0.001    0.000 init.py:202(_calculate_fan_in_and_fan_out)\n",
       "      800    0.001    0.000    0.001    0.000 connection.py:142(_check_writable)\n",
       "      269    0.001    0.000    0.025    0.000 {built-in method builtins.next}\n",
       "      100    0.001    0.000    0.268    0.003 dataloader.py:711(_try_get_data)\n",
       "        1    0.001    0.001    0.025    0.025 nagpreresnet_learned_v2.py:114(__init__)\n",
       "      200    0.001    0.000    0.001    0.000 socket.py:413(close)\n",
       "     67/1    0.001    0.000    0.016    0.016 module.py:822(load)\n",
       "      239    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
       "      300    0.001    0.000    0.001    0.000 {built-in method time.monotonic}\n",
       "      300    0.001    0.000    0.001    0.000 connection.py:168(fileno)\n",
       "      100    0.000    0.000    0.269    0.003 dataloader.py:742(_get_data)\n",
       "        1    0.000    0.000    0.146    0.146 serialization.py:392(_load)\n",
       "      200    0.000    0.000    0.000    0.000 {built-in method _socket.dup}\n",
       "   309/68    0.000    0.000    0.001    0.000 module.py:1015(named_modules)\n",
       "      100    0.000    0.000    0.007    0.000 fromnumeric.py:943(argmax)\n",
       "      100    0.000    0.000    0.793    0.008 Attack_Foolbox_ResNet20.py:155(get_gradient)\n",
       "      120    0.000    0.000    0.001    0.000 threading.py:239(__enter__)\n",
       "      160    0.000    0.000    0.001    0.000 random.py:255(choice)\n",
       "      400    0.000    0.000    0.000    0.000 {method 'ljust' of 'bytes' objects}\n",
       "      188    0.000    0.000    0.064    0.000 utils.py:27(<lambda>)\n",
       "      275    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
       "      266    0.000    0.000    0.001    0.000 module.py:968(named_children)\n",
       "      200    0.000    0.000    0.000    0.000 socket.py:409(_real_close)\n",
       "       37    0.000    0.000    0.003    0.000 iostream.py:197(schedule)\n",
       "      197    0.000    0.000    0.001    0.000 __init__.py:240(__enter__)\n",
       "       76    0.000    0.000    0.000    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
       "      236    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
       "      394    0.000    0.000    0.001    0.000 serialization.py:509(maybe_decode_ascii)\n",
       "      197    0.000    0.000    0.008    0.000 _utils.py:134(_rebuild_tensor_v2)\n",
       "      200    0.000    0.000    0.003    0.000 connection.py:262(__exit__)\n",
       "      160    0.000    0.000    0.001    0.000 random.py:223(_randbelow)\n",
       "      204    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
       "      400    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "      261    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
       "      200    0.000    0.000    0.000    0.000 {method 'setblocking' of '_socket.socket' objects}\n",
       "       57    0.000    0.000    0.000    0.000 {method 'fill_' of 'torch._C._TensorBase' objects}\n",
       "      197    0.000    0.000    0.001    0.000 _utils.py:5(_get_device_index)\n",
       "      266    0.000    0.000    0.001    0.000 module.py:959(children)\n",
       "      120    0.000    0.000    0.001    0.000 threading.py:242(__exit__)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method ones}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method _thread.start_new_thread}\n",
       "      100    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
       "       67    0.000    0.000    0.000    0.000 module.py:755(<dictcomp>)\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:268(close)\n",
       "      494    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
       "        1    0.000    0.000    0.478    0.478 cifar.py:55(__init__)\n",
       "      206    0.000    0.000    0.002    0.000 connection.py:360(_close)\n",
       "      197    0.000    0.000    0.001    0.000 __init__.py:357(device_count)\n",
       "       12    0.000    0.000    0.000    0.000 util.py:151(__init__)\n",
       "      100    0.000    0.000    0.004    0.000 functional.py:1296(log_softmax)\n",
       "      126    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x55641a231e00}\n",
       "      200    0.000    0.000    0.000    0.000 connection.py:83(_validate_family)\n",
       "      395    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_isDriverSufficient}\n",
       "       91    0.000    0.000    0.001    0.000 module.py:143(register_parameter)\n",
       "      100    0.000    0.000    0.001    0.000 <string>:12(__new__)\n",
       "      481    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method zeros}\n",
       "        4    0.000    0.000    2.110    0.528 process.py:95(start)\n",
       "        5    0.000    0.000    0.005    0.001 context.py:99(Queue)\n",
       "        4    0.000    0.000    0.003    0.001 queues.py:155(_start_thread)\n",
       "      197    0.000    0.000    0.001    0.000 __init__.py:236(__init__)\n",
       "      131    0.000    0.000    0.001    0.000 grad_mode.py:41(__exit__)\n",
       "        1    0.000    0.000   52.286   52.286 py3compat.py:184(execfile)\n",
       "      220    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
       "        1    0.000    0.000   52.288   52.288 interactiveshell.py:2673(safe_execfile)\n",
       "      131    0.000    0.000    0.000    0.000 grad_mode.py:37(__enter__)\n",
       "      592    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
       "      258    0.000    0.000    0.000    0.000 reductions.py:32(expired)\n",
       "      131    0.000    0.000    0.000    0.000 grad_mode.py:137(__init__)\n",
       "       17    0.000    0.000    0.000    0.000 threading.py:215(__init__)\n",
       "      197    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDevice}\n",
       "        8    0.000    0.000    0.006    0.001 iostream.py:336(flush)\n",
       "      121    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
       "       20    0.000    0.000    0.002    0.000 tempfile.py:157(__next__)\n",
       "      105    0.000    0.000    0.000    0.000 abc.py:180(__instancecheck__)\n",
       "     67/1    0.000    0.000    0.001    0.001 module.py:1053(train)\n",
       "      200    0.000    0.000    0.000    0.000 {method 'frombytes' of 'array.array' objects}\n",
       "        9    0.000    0.000    0.017    0.002 nagpreresnet_learned_v2.py:28(__init__)\n",
       "      200    0.000    0.000    0.000    0.000 process.py:170(authkey)\n",
       "       19    0.000    0.000    0.000    0.000 {method '_set_from_file' of 'torch._C.CudaLongStorageBase' objects}\n",
       "        5    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BufferedReader' objects}\n",
       "      100    0.000    0.000    0.001    0.000 selectors.py:201(__exit__)\n",
       "      536    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
       "      210    0.000    0.000    0.000    0.000 reductions.py:35(__del__)\n",
       "      200    0.000    0.000    0.000    0.000 {built-in method _socket.CMSG_SPACE}\n",
       "      200    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
       "      203    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedReader' objects}\n",
       "      100    0.000    0.000    0.001    0.000 selectors.py:214(_fileobj_lookup)\n",
       "       22    0.000    0.000    0.004    0.000 init.py:287(kaiming_uniform_)\n",
       "      400    0.000    0.000    0.000    0.000 socket.py:148(__enter__)\n",
       "      105    0.000    0.000    0.001    0.000 utils.py:6(parse)\n",
       "      108    0.000    0.000    0.023    0.000 dataloader.py:317(_next_index)\n",
       "      210    0.000    0.000    0.000    0.000 {built-in method _free_weak_ref}\n",
       "      156    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
       "       25    0.000    0.000    0.001    0.000 weakref.py:165(__setitem__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
       "      100    0.000    0.000    0.000    0.000 {method 'register' of 'select.poll' objects}\n",
       "      119    0.000    0.000    0.000    0.000 threading.py:254(_is_owned)\n",
       "        5    0.000    0.000    0.005    0.001 queues.py:36(__init__)\n",
       "      100    0.000    0.000    0.000    0.000 {built-in method select.poll}\n",
       "      258    0.000    0.000    0.000    0.000 {built-in method _expired}\n",
       "       21    0.000    0.000    0.000    0.000 posixpath.py:75(join)\n",
       "      220    0.000    0.000    0.000    0.000 process.py:35(current_process)\n",
       "      127    0.000    0.000    0.004    0.000 module.py:311(<lambda>)\n",
       "       10    0.000    0.000    1.406    0.141 popen_fork.py:24(poll)\n",
       "      100    0.000    0.000    0.000    0.000 connection.py:913(<listcomp>)\n",
       "      268    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
       "       70    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
       "       45    0.000    0.000    0.000    0.000 threading.py:1104(is_alive)\n",
       "       70    0.000    0.000    0.000    0.000 {built-in method _has_compatible_shallow_copy_type}\n",
       "       20    0.000    0.000    0.001    0.000 tempfile.py:160(<listcomp>)\n",
       "      120    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
       "       70    0.000    0.000    0.000    0.000 module.py:210(compute_should_use_set_data)\n",
       "      210    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
       "      200    0.000    0.000    0.000    0.000 {function socket.detach at 0x7f274a026ae8}\n",
       "        4    0.000    0.000    0.000    0.000 process.py:71(__init__)\n",
       "       19    0.000    0.000    0.001    0.000 argparse.py:1307(add_argument)\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:62(__init__)\n",
       "      230    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
       "      207    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
       "       20    0.000    0.000    0.002    0.000 synchronize.py:114(_make_name)\n",
       "       18    0.000    0.000    0.002    0.000 iostream.py:384(write)\n",
       "        4    0.000    0.000    2.110    0.527 context.py:274(_Popen)\n",
       "      201    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
       "       11    0.000    0.000    0.006    0.001 threading.py:263(wait)\n",
       "       12    0.000    0.000    0.007    0.001 threading.py:533(wait)\n",
       "       19    0.000    0.000    0.006    0.000 batchnorm.py:87(_load_from_state_dict)\n",
       "       25    0.000    0.000    0.000    0.000 weakref.py:339(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 init.py:27(_no_grad_zero_)\n",
       "      262    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}\n",
       "       11    0.000    0.000    0.003    0.000 context.py:64(Lock)\n",
       "      125    0.000    0.000    0.000    0.000 module.py:594(remove_from)\n",
       "      100    0.000    0.000    0.000    0.000 _reduction.py:6(get_enum)\n",
       "      2/1    0.000    0.000   52.288   52.288 {built-in method builtins.exec}\n",
       "       19    0.000    0.000    0.001    0.000 batchnorm.py:43(reset_running_stats)\n",
       "       70    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:157(__init__)\n",
       "       32    0.000    0.000    0.000    0.000 Attack_Foolbox_ResNet20.py:47(<genexpr>)\n",
       "      197    0.000    0.000    0.000    0.000 __init__.py:164(_lazy_init)\n",
       "       21    0.000    0.000    0.004    0.000 conv.py:48(reset_parameters)\n",
       "      178    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.FloatStorageBase' objects}\n",
       "        4    0.000    0.000    2.109    0.527 popen_fork.py:16(__init__)\n",
       "       21    0.000    0.000    0.009    0.000 conv.py:321(__init__)\n",
       "       25    0.000    0.000    0.001    0.000 util.py:136(register_after_fork)\n",
       "      200    0.000    0.000    0.000    0.000 connection.py:259(__enter__)\n",
       "        2    0.000    0.000    1.407    0.703 dataloader.py:872(_shutdown_workers)\n",
       "       22    0.000    0.000    0.000    0.000 init.py:32(calculate_gain)\n",
       "        9    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
       "      197    0.000    0.000    0.000    0.000 __init__.py:248(__exit__)\n",
       "      197    0.000    0.000    0.000    0.000 serialization.py:63(_cpu_deserialize)\n",
       "      262    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}\n",
       "       12    0.000    0.000    0.000    0.000 threading.py:498(__init__)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:757(__init__)\n",
       "       19    0.000    0.000    0.002    0.000 batchnorm.py:49(reset_parameters)\n",
       "        5    0.000    0.000    0.000    0.000 queues.py:67(_after_fork)\n",
       "        1    0.000    0.000    0.003    0.003 cifar.py:97(_load_meta)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1444(_get_optional_kwargs)\n",
       "        1    0.000    0.000    0.147    0.147 serialization.py:305(load)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:466(find)\n",
       "      100    0.000    0.000    0.000    0.000 {method '_weak_ref' of 'torch._C.FloatStorageBase' objects}\n",
       "       19    0.000    0.000    0.000    0.000 init.py:22(_no_grad_fill_)\n",
       "        7    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:275(_key_from_fd)\n",
       "      100    0.000    0.000    0.000    0.000 {method '_weak_ref' of 'torch._C.LongStorageBase' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.putenv}\n",
       "      100    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1775(_parse_known_args)\n",
       "      103    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
       "      160    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
       "        4    0.000    0.000    0.006    0.002 util.py:395(_flush_std_streams)\n",
       "        7    0.000    0.000    0.404    0.058 utils.py:32(check_md5)\n",
       "       45    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
       "        3    0.000    0.000    0.018    0.006 nagpreresnet_learned_v2.py:149(_make_layer)\n",
       "      110    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
       "       25    0.000    0.000    0.000    0.000 os.py:664(__getitem__)\n",
       "        6    0.000    0.000    0.000    0.000 gettext.py:205(_expand_lang)\n",
       "        4    0.000    0.000    0.003    0.001 threading.py:828(start)\n",
       "       22    0.000    0.000    0.000    0.000 weakref.py:109(remove)\n",
       "       20    0.000    0.000    0.000    0.000 tempfile.py:146(rng)\n",
       "        5    0.000    0.000    0.000    0.000 connection.py:501(Pipe)\n",
       "        4    0.000    0.000    1.406    0.351 process.py:118(join)\n",
       "        8    0.000    0.000    0.001    0.000 util.py:167(__call__)\n",
       "       51    0.000    0.000    0.000    0.000 re.py:286(_compile)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'bytes' objects}\n",
       "       18    0.000    0.000    0.000    0.000 iostream.py:309(_is_master_process)\n",
       "       25    0.000    0.000    0.000    0.000 weakref.py:334(__new__)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
       "       37    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
       "        4    0.000    0.000    2.110    0.527 context.py:221(_Popen)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
       "       68    0.000    0.000    0.001    0.000 module.py:988(modules)\n",
       "       22    0.000    0.000    0.001    0.000 init.py:277(_calculate_correct_fan)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1364(_add_action)\n",
       "        1    0.000    0.000    0.406    0.406 cifar.py:135(_check_integrity)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1226(__init__)\n",
       "      100    0.000    0.000    0.000    0.000 selectors.py:198(__enter__)\n",
       "        7    0.000    0.000    0.408    0.058 utils.py:36(check_integrity)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method empty}\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:1843(consume_optional)\n",
       "        4    0.000    0.000    0.000    0.000 queues.py:147(cancel_join_thread)\n",
       "       70    0.000    0.000    0.000    0.000 __future__.py:18(get_overwrite_module_params_on_conversion)\n",
       "        5    0.000    0.000    0.001    0.000 context.py:84(BoundedSemaphore)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:2352(_get_formatter)\n",
       "       29    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
       "       18    0.000    0.000    0.008    0.000 nagpreresnet_learned_v2.py:19(conv3x3)\n",
       "       27    0.000    0.000    0.000    0.000 os.py:742(encode)\n",
       "       48    0.000    0.000    0.000    0.000 argparse.py:1282(_registry_get)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:580(_format_args)\n",
       "       10    0.000    0.000    0.001    0.000 activation.py:89(__init__)\n",
       "       53    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2234(_get_values)\n",
       "        8    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
       "        5    0.000    0.000    0.001    0.000 container.py:46(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:1822(take_action)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2050(_match_argument)\n",
       "       41    0.000    0.000    0.000    0.000 re.py:231(compile)\n",
       "       19    0.000    0.000    0.000    0.000 {built-in method _new_with_weak_ptr}\n",
       "        1    0.000    0.000    2.124    2.124 dataloader.py:274(__iter__)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:154(dirname)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1604(__init__)\n",
       "        8    0.000    0.000    0.005    0.001 genericpath.py:27(isfile)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
       "       27    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
       "       18    0.000    0.000    0.000    0.000 argparse.py:835(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._set_worker_pids}\n",
       "        5    0.000    0.000    0.000    0.000 threading.py:1230(current_thread)\n",
       "       29    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
       "       67    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}\n",
       "       37    0.000    0.000    0.000    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:120(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:174(nti)\n",
       "       34    0.000    0.000    0.000    0.000 argparse.py:1278(register)\n",
       "       11    0.000    0.000    0.003    0.000 synchronize.py:161(__init__)\n",
       "        4    0.000    0.000    1.406    0.351 popen_fork.py:43(wait)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1555(_add_action)\n",
       "        6    0.000    0.000    0.000    0.000 locale.py:379(normalize)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:257(_EndRecData)\n",
       "        7    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:338(normpath)\n",
       "       32    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
       "       45    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
       "       45    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:301(__init__)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:793(__init__)\n",
       "       26    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
       "       69    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1480(_pop_action_class)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:573(format)\n",
       "       53    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
       "        4    0.000    0.000    0.000    0.000 util.py:191(cancel)\n",
       "       28    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
       "       11    0.000    0.000    0.000    0.000 module.py:182(add_module)\n",
       "        4    0.000    0.000    0.000    0.000 process.py:52(_cleanup)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1713(_add_action)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:202(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:1024(frombuf)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1740(parse_known_args)\n",
       "       20    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
       "    14/13    0.000    0.000    0.000    0.000 dataloader.py:267(__setattr__)\n",
       "        5    0.000    0.000    0.000    0.000 dataloader.py:703(<genexpr>)\n",
       "        4    0.000    0.000    0.000    0.000 dataloader.py:849(_shutdown_worker)\n",
       "       19    0.000    0.000    0.000    0.000 init.py:123(ones_)\n",
       "        1    0.000    0.000    0.115    0.115 tarfile.py:2276(next)\n",
       "       11    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:68(__init__)\n",
       "        1    0.000    0.000    0.115    0.115 tarfile.py:1411(__init__)\n",
       "       22    0.000    0.000    0.000    0.000 {built-in method _weakref._remove_dead_weakref}\n",
       "        4    0.000    0.000    0.001    0.000 queues.py:131(close)\n",
       "        4    0.000    0.000    0.000    0.000 queues.py:196(_finalize_close)\n",
       "        4    0.000    0.000    0.001    0.000 context.py:79(Semaphore)\n",
       "        5    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)\n",
       "       42    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
       "        2    0.000    0.000    0.000    0.000 signal_handling.py:63(handler)\n",
       "       19    0.000    0.000    0.000    0.000 init.py:137(zeros_)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:89(Event)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:212(__init__)\n",
       "        1    0.000    0.000    0.016    0.016 module.py:794(load_state_dict)\n",
       "        7    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_md5}\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2286(_get_value)\n",
       "       27    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
       "       11    0.000    0.000    0.000    0.000 threading.py:251(_acquire_restore)\n",
       "        1    0.000    0.000    0.000    0.000 signal_handling.py:47(_set_SIGCHLD_handler)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
       "        8    0.000    0.000    0.000    0.000 process.py:83(<genexpr>)\n",
       "       10    0.000    0.000    0.000    0.000 {method 'group' of '_sre.SRE_Match' objects}\n",
       "       29    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
       "       43    0.000    0.000    0.000    0.000 {method 'islower' of 'str' objects}\n",
       "       18    0.000    0.000    0.000    0.000 iostream.py:322(_schedule_flush)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:55(__exit__)\n",
       "       20    0.000    0.000    0.000    0.000 argparse.py:2087(_parse_optional)\n",
       "       12    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
       "       19    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:572(dgettext)\n",
       "        2    0.000    0.000    0.000    0.000 {built-in method torch._C._error_if_any_worker_fails}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:287(notify_all)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:345(set)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:2071(_match_arguments_partial)\n",
       "       10    0.000    0.000    0.000    0.000 re.py:169(match)\n",
       "        6    0.000    0.000    0.000    0.000 _collections_abc.py:657(get)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:564(_metavar_formatter)\n",
       "       40    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
       "       19    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.LongStorageBase' objects}\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:2363(_check)\n",
       "        1    0.000    0.000    0.115    0.115 serialization.py:455(legacy_load)\n",
       "       10    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
       "       19    0.000    0.000    0.000    0.000 argparse.py:1493(_check_conflict)\n",
       "        9    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1533(__init__)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2190(_get_nargs_pattern)\n",
       "        1    0.000    0.000    0.000    0.000 vision.py:9(__init__)\n",
       "        1    0.000    0.000   52.288   52.288 <string>:1(<module>)\n",
       "       11    0.000    0.000    0.000    0.000 threading.py:248(_release_save)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:232(__exit__)\n",
       "        1    0.000    0.000    0.000    0.000 linear.py:79(reset_parameters)\n",
       "        1    0.000    0.000    0.115    0.115 tarfile.py:1087(fromtarfile)\n",
       "       20    0.000    0.000    0.000    0.000 context.py:196(get_start_method)\n",
       "        4    0.000    0.000    0.000    0.000 process.py:190(ident)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:94(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:229(__enter__)\n",
       "        1    0.000    0.000    0.115    0.115 tarfile.py:1522(open)\n",
       "        1    0.000    0.000    0.001    0.001 Attack_Foolbox_ResNet20.py:97(__init__)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:232(expanduser)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:376(abspath)\n",
       "        1    0.000    0.000    0.025    0.025 nagpreresnet_learned_v2.py:188(nagpreresnet_learned_v2)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:46(__exit__)\n",
       "        2    0.000    0.000    0.000    0.000 argparse.py:1354(add_argument_group)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:1950(<listcomp>)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:506(translation)\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
       "       10    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
       "       18    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:61(__iter__)\n",
       "        1    0.000    0.000    0.000    0.000 shape_base.py:63(atleast_2d)\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:48(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:97(__exit__)\n",
       "        5    0.000    0.000    0.001    0.000 synchronize.py:144(__init__)\n",
       "        5    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.024    0.024 shape_base.py:182(vstack)\n",
       "       21    0.000    0.000    0.000    0.000 context.py:186(get_context)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:864(__call__)\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:1136(daemon)\n",
       "        1    0.000    0.000    0.000    0.000 os.py:672(__setitem__)\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method _imp.lock_held}\n",
       "        1    0.000    0.000    0.000    0.000 pooling.py:539(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:179(_check_seekable)\n",
       "        1    0.000    0.000    0.000    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
       "        4    0.000    0.000    0.000    0.000 threading.py:1120(daemon)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
       "        8    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
       "        4    0.000    0.000    0.001    0.000 synchronize.py:125(__init__)\n",
       "        1    0.000    0.000    0.115    0.115 tarfile.py:1613(taropen)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1011(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 argparse.py:1484(_get_handler)\n",
       "       10    0.000    0.000    0.000    0.000 argparse.py:2312(_check_value)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:155(_is_compressed_file)\n",
       "        1    0.000    0.000    0.001    0.001 context.py:74(Condition)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
       "        3    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
       "        1    0.000    0.000    0.001    0.001 synchronize.py:334(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:182(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 serialization.py:163(_should_read_directly)\n",
       "        1    0.000    0.000    0.000    0.000 numeric.py:495(asanyarray)\n",
       "        3    0.000    0.000    0.001    0.000 gettext.py:611(gettext)\n",
       "        1    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:132(__len__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:239(multiprocessing_context)\n",
       "        1    0.000    0.000    0.000    0.000 tarfile.py:166(nts)\n",
       "        1    0.000    0.000    0.001    0.001 argparse.py:1733(parse_args)\n",
       "        2    0.000    0.000    0.000    0.000 posixpath.py:64(isabs)\n",
       "        1    0.000    0.000    0.000    0.000 posixpath.py:144(basename)\n",
       "        1    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
       "        5    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
       "        1    0.000    0.000    0.000    0.000 cifar.py:108(<dictcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:12(_no_grad_uniform_)\n",
       "        1    0.000    0.000    0.007    0.007 module.py:297(cuda)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:198(is_zipfile)\n",
       "        1    0.000    0.000    0.000    0.000 shape_base.py:234(<listcomp>)\n",
       "        4    0.000    0.000    0.000    0.000 process.py:162(daemon)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1920(consume_positionals)\n",
       "        3    0.000    0.000    0.000    0.000 os.py:746(decode)\n",
       "        4    0.000    0.000    0.000    0.000 {method 'clear' of 'collections.deque' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
       "        4    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
       "        2    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
       "        6    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._remove_worker_pids}\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:284(_index_sampler)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:925(__del__)\n",
       "        1    0.000    0.000    0.001    0.001 zipfile.py:190(_check_zipfile)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
       "        1    0.000    0.000    0.000    0.000 syspathcontext.py:45(__init__)\n",
       "        8    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
       "        1    0.000    0.000    0.000    0.000 attack_toolbox.py:23(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 transforms.py:56(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 vision.py:55(__init__)\n",
       "        3    0.000    0.000    0.000    0.000 dataloader.py:280(_auto_collation)\n",
       "        1    0.000    0.000    0.001    0.001 module.py:1073(eval)\n",
       "        1    0.000    0.000    0.000    0.000 Attack_Foolbox_ResNet20.py:96(PytorchModel)\n",
       "        1    0.000    0.000    0.000    0.000 builtin_trap.py:39(__enter__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1642(identity)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1726(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1725(_get_positional_actions)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'find' of 'bytes' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
       "        1    0.000    0.000    0.000    0.000 synchronize.py:235(_make_methods)\n",
       "        1    0.000    0.000    0.000    0.000 sampler.py:58(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 dataloader.py:235(multiprocessing_context)\n",
       "        1    0.000    0.000    0.000    0.000 init.py:74(uniform_)\n",
       "        1    0.000    0.000    0.000    0.000 {method '_is_mine' of '_multiprocessing.SemLock' objects}\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:1211(__init__)\n",
       "        1    0.000    0.000    0.000    0.000 argparse.py:595(<listcomp>)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
       "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.999-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.999 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.99 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.95-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.95 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.9-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.9 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.7-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.7 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.5-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.5 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.3-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.3 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.1-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.1 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.01-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.01 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.001-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5 \n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet20-basicblock-eta-0.0001-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_learned\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_learned\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_learned\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_learned\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned20-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_learned\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-0/model_best.pth.tar\" -a \"nagpreresnet_learned_v2\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-1/model_best.pth.tar\" -a \"nagpreresnet_learned_v2\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-2/model_best.pth.tar\" -a \"nagpreresnet_learned_v2\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-3/model_best.pth.tar\" -a \"nagpreresnet_learned_v2\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5\n",
    "%run -p Attack_Foolbox_ResNet20.py --checkpoint \"/tanresults/experiments-horesnet/cifar10-nagpreresnet_learned_v220-basicblock-eta-0.99-x-baolr-pgd-seed-4/model_best.pth.tar\" -a \"nagpreresnet_learned_v2\" --block-name \"basicblock\" --feature_vec \"x\" --dataset \"cifar10\" --eta 0.0001 --depth 20 --method fgsm --epsilon 0.031 --gpu-id 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
